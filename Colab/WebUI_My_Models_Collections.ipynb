{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MOHOAzure/AI_Paint_Online/blob/main/Colab/WebUI_My_Models_Collections.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfKvWAVnz8OB"
      },
      "source": [
        "Thanks for your contributions\n",
        "\n",
        "藏經閣\n",
        "https://drive.google.com/drive/folders/1vGc16Bb8CDW1piUj_5thzbsCmDFamYyt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3bn_Nb798yRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5772a6e9-01ae-4ac1-8776-4ed645732529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "Cloning into 'stable-diffusion-webui'...\n",
            "remote: Enumerating objects: 22291, done.\u001b[K\n",
            "remote: Counting objects: 100% (437/437), done.\u001b[K\n",
            "remote: Compressing objects: 100% (257/257), done.\u001b[K\n",
            "remote: Total 22291 (delta 243), reused 300 (delta 160), pack-reused 21854\u001b[K\n",
            "Receiving objects: 100% (22291/22291), 30.33 MiB | 17.82 MiB/s, done.\n",
            "Resolving deltas: 100% (15570/15570), done.\n",
            "/content/stable-diffusion-webui/extensions\n",
            "Cloning into 'ultimate-upscale-for-automatic1111'...\n",
            "remote: Enumerating objects: 296, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 296 (delta 27), reused 63 (delta 22), pack-reused 225\u001b[K\n",
            "Receiving objects: 100% (296/296), 32.23 MiB | 17.21 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n",
            "Cloning into 'multidiffusion-upscaler-for-automatic1111'...\n",
            "remote: Enumerating objects: 993, done.\u001b[K\n",
            "remote: Counting objects: 100% (192/192), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 993 (delta 106), reused 159 (delta 96), pack-reused 801\u001b[K\n",
            "Receiving objects: 100% (993/993), 1.13 MiB | 2.26 MiB/s, done.\n",
            "Resolving deltas: 100% (529/529), done.\n"
          ]
        }
      ],
      "source": [
        "#@title Setup Tool to use models on My Drive\n",
        "\n",
        "# (optional: check GPU)\n",
        "# !nvidia-smi\n",
        "\n",
        "# load Google Drive for my models\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# param from user\n",
        "version = 'latest' #@param [\"latest\", \"685f9631b56ff8bd43bce24ff5ce0f9a0e9af490\"] {allow-input: true}\n",
        "\n",
        "# model selection\n",
        "model_and_misc_dir = '/content/drive/Shareddrives/AI_Paint/SD'\n",
        "\n",
        "## the model dir where the tool can find models\n",
        "model_dir = \"models\" #@param {type:\"string\"}\n",
        "\n",
        "## specific model under the model dir, including extension\n",
        "model_filename = \"ghostmix_v12.safetensors\" #@param [\"meinamix_meinaV51.safetensors\", \"ghostmix_v12.safetensors\", \"majicmixRealistic_v4\"] {allow-input: true}\n",
        "\n",
        "## select extensions\n",
        "use_regional_prompter = False # @param {type:\"boolean\"}\n",
        "use_supermerge = False # @param {type:\"boolean\"}\n",
        "use_specific_model = False #@param {type:\"boolean\"}\n",
        "use_cuda = True # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# define variables such as working directory\n",
        "root_dir = Path(\"/content\")\n",
        "model_and_misc_dir = Path(model_and_misc_dir)\n",
        "model_dir = model_and_misc_dir/model_dir\n",
        "\n",
        "## load tool info\n",
        "json_path = model_and_misc_dir/\"tool.json\"\n",
        "with open(json_path, \"r\") as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "tool_name = data[\"tool_name\"]\n",
        "repo = data[\"repo\"]\n",
        "tool_dir = root_dir/tool_name\n",
        "\n",
        "\n",
        "def use_cuda():\n",
        "  # use cuda instead of cpu for large model (e.g., 7G)\n",
        "  !sed -i 's/weight_load_location = None if cmd_opts.lowram else \"cpu\"/weight_load_location = None if cmd_opts.lowram else \"cuda\"/g' {tool_dir}/modules/shared.py\n",
        "\n",
        "def install_dep():\n",
        "  # install xformers & its dep.\n",
        "  %cd {root_dir}\n",
        "  !pip install -q torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1+cu118 torchtext==0.15.1 torchdata==0.6.0 --extra-index-url https://download.pytorch.org/whl/cu118 -U\n",
        "  !pip install -q xformers==0.0.18 triton==2.0.0 -U\n",
        "\n",
        "def install_extentions():\n",
        "  %cd {tool_dir}/extensions\n",
        "  \n",
        "  # Commonly used extention\n",
        "  !git clone https://github.com/Coyote-A/ultimate-upscale-for-automatic1111.git\n",
        "  !git clone https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111.git\n",
        "  \n",
        "\n",
        "%cd $root_dir\n",
        "\n",
        "# install tool\n",
        "!git clone $repo\n",
        "\n",
        "# time machine: commit or branch\n",
        "if version != 'latest':\n",
        "  %cd {tool_dir}\n",
        "  !git checkout $version\n",
        "\n",
        "# install_dep() // Deprecated\n",
        "install_extentions()\n",
        "\n",
        "# load tool config\n",
        "!cp {model_and_misc_dir}/\"[template] ui-config.json\" {tool_dir}/ui-config.json\n",
        "!cp {model_and_misc_dir}/\"[template] config.json\" {tool_dir}/config.json\n",
        "\n",
        "if use_specific_model:\n",
        "  model = model_dir / model_filename\n",
        "\n",
        "\n",
        "if use_cuda:\n",
        "  use_cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SqVOOeFsmF-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1721d033-dd3b-40e6-86a8-cdef27021fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stable-diffusion-webui/extensions\n",
            "Cloning into 'sd-webui-controlnet'...\n",
            "remote: Enumerating objects: 7258, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 7258 (delta 81), reused 98 (delta 64), pack-reused 7138\u001b[K\n",
            "Receiving objects: 100% (7258/7258), 15.83 MiB | 10.50 MiB/s, done.\n",
            "Resolving deltas: 100% (3974/3974), done.\n",
            "/content/stable-diffusion-webui/models/ControlNet\n",
            "--2023-06-07 14:34:54--  https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile.pth\n",
            "Resolving huggingface.co (huggingface.co)... 18.155.68.38, 18.155.68.121, 18.155.68.116, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.155.68.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libcairo2-dev is already the newest version (1.16.0-4ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: svglib in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.10/dist-packages (from svglib) (4.0.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from svglib) (4.9.2)\n",
            "Requirement already satisfied: tinycss2>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from svglib) (1.2.1)\n",
            "Requirement already satisfied: cssselect2>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from svglib) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from cssselect2>=0.2.0->svglib) (0.5.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab->svglib) (9.5.0)\n"
          ]
        }
      ],
      "source": [
        "#@title Install extension: controlnet\n",
        "\n",
        "use_controlnet = True # @param {type:\"boolean\"}\n",
        "\n",
        "if use_controlnet:\n",
        "  # @markdown ---\n",
        "  # @markdown - ControlNet tool: https://github.com/lllyasviel/ControlNet\n",
        "  # @markdown - Models: https://huggingface.co/lllyasviel/ControlNet-v1-1/tree/main\n",
        "  # @markdown - Alt models: https://huggingface.co/webui/ControlNet-modules-safetensors/\n",
        "  # @markdown - To enlarge the potential of AI, the following settings could be configured. \n",
        "  # @markdown  - Lower Control weight & Lower Ending Step. E.g., 0.5\n",
        "  # @markdown  - Higher Down Sampling rate. E.g., 2\n",
        "  # @markdown ---\n",
        "  # @markdown - Settings\n",
        "  control_tile = True # @param {type:\"boolean\"}\n",
        "  # @markdown - Tile is basically for high res upscaling. However, it can get much more context than other upscalers. It can replace the traditional process of drawing images by relying on its understanding of images. The option `Prompt is more important` is useful. The preprocessor is `tile_resample`.\n",
        "\n",
        "  control_inpaint = False # @param {type:\"boolean\"}\n",
        "  # @markdown - Inpaint is for painting to specific regions of the image. The preprocessor is `inpaint_global_harmonious`\n",
        "\n",
        "  control_lineart = False # @param {type:\"boolean\"}  \n",
        "  # @markdown - Lineart is for composition control. Normal, need to enlarge the potential of AI (see above notes). The preprocessor is `lineart_realistic`\n",
        "\n",
        "  # TODO: update name\n",
        "  # control_seg = False # @param {type:\"boolean\"}\n",
        "  # control_openpose = False # @param {type:\"boolean\"}\n",
        "  # control_canny = False # @param {type:\"boolean\"}\n",
        "  # control_depth = False # @param {type:\"boolean\"}\n",
        "  # control_hed = False # @param {type:\"boolean\"}\n",
        "  # control_mlsd = False # @param {type:\"boolean\"}\n",
        "  # control_normal = False # @param {type:\"boolean\"}\n",
        "  # control_scribble = False # @param {type:\"boolean\"}\n",
        "  # t2iadapter_keypose = False # @param {type:\"boolean\"}\n",
        "  # t2iadapter_openpose = False # @param {type:\"boolean\"}\n",
        "  # t2iadapter_seg = False # @param {type:\"boolean\"}\n",
        "  # t2iadapter_sketch = False # @param {type:\"boolean\"}\n",
        "\n",
        "  control_net_models = []\n",
        "  if control_tile == True:\n",
        "      control_net_models.append(\"control_v11f1e_sd15_tile\")\n",
        "  if control_inpaint == True:\n",
        "      control_net_models.append(\"control_v11p_sd15_inpaint\")\n",
        "  if control_lineart == True:\n",
        "      control_net_models.append(\"control_v11p_sd15_lineart\")      \n",
        "      \n",
        "  # TODO: update name\n",
        "  # if t2iadapter_keypose == True:\n",
        "  #     control_net_models.append(\"t2iadapter_keypose\")\n",
        "  # if t2iadapter_seg == True:\n",
        "  #     control_net_models.append(\"t2iadapter_seg\")\n",
        "  # if t2iadapter_sketch == True:\n",
        "  #     control_net_models.append(\"t2iadapter_sketch\")\n",
        "  # if t2iadapter_openpose == True:\n",
        "  #     control_net_models.append(\"t2iadapter_openpose\")\n",
        "  # if control_canny == True:\n",
        "  #     control_net_models.append(\"control_canny\")\n",
        "  # if control_depth == True:\n",
        "  #     control_net_models.append(\"control_depth\")\n",
        "  # if control_hed == True:\n",
        "  #     control_net_models.append(\"control_hed\")\n",
        "  # if control_mlsd == True:\n",
        "  #     control_net_models.append(\"control_mlsd\")\n",
        "  # if control_normal == True:\n",
        "  #     control_net_models.append(\"control_normal\")\n",
        "  # if control_openpose == True:\n",
        "  #     control_net_models.append(\"control_openpose\")\n",
        "  # if control_scribble == True:\n",
        "  #     control_net_models.append(\"control_scribble\")\n",
        "  # if control_seg == True:\n",
        "  #     control_net_models.append(\"control_seg\")\n",
        "\n",
        "  %cd {tool_dir}/extensions\n",
        "  name_part_1 = \"https://github.com/Mikubill/sd\"\n",
        "  name_part_2 = \"-webui-controlnet.git\"\n",
        "  !git clone \"{name_part_1}{name_part_2}\"\n",
        "  # !git clone https://github.com/lllyasviel/ControlNet.git  \n",
        "  # !git clone https://github.com/fkunn1326/openpose-editor.git\n",
        "\n",
        "  ! mkdir -p {tool_dir}/models/ControlNet\n",
        "  %cd {tool_dir}/models/ControlNet\n",
        "  for control_net_model in control_net_models:\n",
        "    ! wget -nc --content-disposition https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/{control_net_model}.pth\n",
        "    #E.g., https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile.pth\n",
        "\n",
        "  # install dep\n",
        "  !apt install libcairo2-dev\n",
        "  !pip install svglib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt8lbdmC04ox"
      },
      "source": [
        "# Launch\n",
        "Provide a directory to models (sub dir is optional) and then run this script. You will get something like xxx.gradio.app, click it to go to the deployed Web UI.\n",
        "\n",
        "---\n",
        "\n",
        "This script use some parameters to run Web UI.\n",
        "\n",
        "The following parameters are the most important ones for use via colab & gradio:\n",
        "  - `--share` - create an online gradio.app link\n",
        "  - `--gradio-debug` - print output to console\n",
        "  - `--gradio-auth YOUR_ACCOUNT:YOUR_PWD` - create a login account\n",
        "\n",
        "*   In order to prevent others from crawling your online deployment for use, it is strongly recommended to modify the username and password, and `replace account & password with others`.\n",
        "\n",
        "---\n",
        "My Quality Prompt\n",
        "> dramatic lighting,  HDR,  cinematic,  dark lighting,  cinematic lighting,  cinematic bloom\n",
        "\n",
        "> 1girl, (close to viewer:1.4), Perfect details,extremely fine and beautiful, Amazing,beautiful background,finely detail,Depth of field,extremely detailed 8k wallpaper,(magnificent), ((best quality)), ((masterpiece)), ((ultra-detailed)), ((an extremely delicate and beautiful),((extremely detailed)), optical, reflective, epic,Hyperdetail, global illumination, epic scenes, beautiful and delicate\n",
        "\n",
        "> beautiful complex, oil on canvas, (masterpiece:1.3),(best quality,ultra-detailed,illustration:1.2), (extremely detailed cg,8k,high resolution), flawless, clean, supreme detail, highly detailed, sharp focus, professional artwork, famous artwork, cinematic lighting, cinematic bloom\n",
        "\n",
        "> (best quality), (realistic), (photorealistic), extremely detailed, RAW photo,\n",
        "real face, real skin, realistic face, realistic skin, detailed eyes, detailed facial features, detailed clothes features, detailed face and breast, beautiful eyes, detailed eyes, perfect body, perfect breasts, perfect face,\n",
        "\n",
        "> FOREGROUND, REFLECTION, SACREDNESS, LANDSCAPE, BRIGHT, FHD, 4K, HIGH RESOLUTION, HYPERREALISM, (photorealistic, realistic, RAW photo:1.3), (masterpiece, best quality, ultra highres, ultra-detailed:1.5)\n",
        "\n",
        "My Negative Prompts:\n",
        "> (frown:1.5). (text, title, logo, signature:1.5), (worst quality, low quality:1.4), (realistic, lip, nose, tooth, rouge, lipstick, eyeshadow:1.0), (dusty sunbeams:1.0), (abs, muscular, rib:1.0), (depth of field, bokeh, blurry:1.4), (greyscale, monochrome:1.0)\n",
        "\n",
        "> (lowres, blurry, worst quality, low quality:1.21), normal quality, multiple breasts, (mutated hands and fingers:1.5), (long body:1.3), (mutation, poorly drawn:1.2), black-white, bad anatomy, disfigured, deformed, mutation, mutilated, ugly, poorly drawn face, cloned face, (unclear blurry eyes:1.331), bad eyes, fused eyes, poorly drawn eyes, extra eyes, long neck, bad hands, poorly drawn hands, multiple limbs, extra limbs, malformed limbs, missing arms, missing fingers, interlocked fingers, extra fingers, fused fingers, too many fingers, long nails, missing legs, extra legs, broken legs, bad feet, extra digit, fewer digits, glitchy, (jpeg artifacts, ((signature, watermark, username)), text, error, multiple_views, reference_sheet)\n",
        "\n",
        "Common Negative Prompts:\n",
        "> lowres, blurry, worst quality, low quality, normal quality,bad anatomy, disfigured, deformed, mutation, mutilated, ugly, totem pole,poorly drawn face,  cloned face, several faces, long neck, mutated hands, bad hands, poorly drawn hands,extra limbs, malformed limbs, missing arms, missing fingers, extra fingers, fused fingers, too many fingers,missing legs, extra legs, malformed legs, extra digit, fewer digits, glitchy, cropped, jpeg artifacts, signature, watermark, username, text, error\n",
        "\n",
        "> plain background, poorly drawn face, poorly drawn hands, watermark, censored, (mutated hands and fingers), ugly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-xAdMA5wxXd"
      },
      "outputs": [],
      "source": [
        "#@title Launch\n",
        "%cd {tool_dir}\n",
        "\n",
        "# security\n",
        "account = \"MY_ACCOUNT\" #@param {type:\"string\"}\n",
        "pwd = \"MY_PWD\" #@param {type:\"string\"}\n",
        "\n",
        "load_model_cmd = f\"--ckpt-dir {model_dir}\"\n",
        "\n",
        "if use_specific_model:\n",
        "  load_model_cmd = f\"--ckpt {model}\"\n",
        "else:\n",
        "  # update the first model to load\n",
        "  !sed -i \"s#THE_FIRST_MODEL.ext#{model_filename}#g\" {tool_dir}/config.json\n",
        "\n",
        "# use param to run tool\n",
        "# --no-progressbar-hiding (may slow down)\n",
        "# Speed to gen pic: --opt-split-attention OR --xformers\n",
        "# --no-hashing\n",
        "# --opt-sdp-no-mem-attention --opt-channelslast\n",
        "arg = f\"--opt-sdp-attention --opt-channelslast --no-half-vae --share --gradio-debug --gradio-auth {account}:{pwd} --disable-safe-unpickle --enable-insecure-extension-access {load_model_cmd}\"\n",
        "\n",
        "!COMMANDLINE_ARGS=\"{arg}\" REQS_FILE=\"requirements.txt\" python launch.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}